{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('train.pkl', 'rb')\n",
    "train = pickle.load(file)\n",
    "file = open('test.pkl', 'rb')\n",
    "test =  pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_rename = []\n",
    "cols_values = []\n",
    "for i in range(1, 39):\n",
    "  c=''\n",
    "  if i<10:\n",
    "    c='0'\n",
    "  cols_to_rename += ['id-'+ c + str(i)]\n",
    "  cols_values += ['id_'+ c + str(i)]\n",
    "test = test.rename(columns=dict(zip(cols_to_rename, cols_values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_lotof_nulls = [c for c in train.columns if (train[c].isnull().sum() / train.shape[0])>0.9]\n",
    "cols_lotof_nulls_test = [c for c in test.columns if (test[c].isnull().sum() / test.shape[0])>0.9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_with_single_values = [c for c in train.columns if (train[c].nunique() == 1)]\n",
    "cols_with_single_values_test = [c for c in test.columns if (test[c].nunique() == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols_to_drop = list(set(cols_lotof_nulls+ cols_lotof_nulls_test+ cols_with_single_values+ cols_with_single_values_test))\n",
    "len(cols_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(cols_to_drop, axis=1)\n",
    "test = test.drop(cols_to_drop, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['id_12', 'id_13', 'id_14', 'id_15', 'id_16', 'id_17', 'id_18',\n",
    "            'id_19', 'id_20', 'id_21', 'id_22', 'id_23', 'id_24', 'id_25',\n",
    "            'id_26', 'id_27', 'id_28', 'id_29', 'id_30', 'id_31', 'id_32', \n",
    "            'id_33', 'id_34', 'id_35', 'id_36', 'id_37','id_38', 'DeviceType', \n",
    "            'DeviceInfo', 'ProductCD','P_emaildomain','R_emaildomain',\n",
    "            'M1','M2','M3','M4','M5','M6','M7','M8', 'M9', 'P_emaildomain_1', \n",
    "            'P_emaildomain_2', 'P_emaildomain_3', 'R_emaildomain_1', 'R_emaildomain_2', \n",
    "            'R_emaildomain_3', 'card4', 'card3', 'card2', 'card1', 'card5', 'card6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in cat_cols:\n",
    "  if col in train.columns:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(list(train[col].astype(str).values) + list(test[col].astype(str).values))\n",
    "    train[col] = le.transform(list(train[col].astype('str').values))\n",
    "    test[col] = le.transform(list(test[col].astype('str').values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.replace([np.inf, -np.inf], np.nan)\n",
    "test = test.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(['level_0', 'index', 'isFraud', 'TransactionID'], axis=1)#[:10000]\n",
    "y = train.isFraud#[:10000]\n",
    "\n",
    "X = train.drop(['level_0', 'index', 'TransactionID'], axis=1)\n",
    "test_cols = X.columns.tolist()\n",
    "test_cols.remove('isFraud')\n",
    "test = test[test_cols].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((590540, 58), (590540, 58))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoGloun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No output_directory specified. Models will be saved in: AutogluonModels/ag-20201119_065829/\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to AutogluonModels/ag-20201119_065829/\n",
      "AutoGluon Version:  0.0.14\n",
      "Train Data Rows:    590540\n",
      "Train Data Columns: 58\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [0, 1]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    10790.88 MB\n",
      "\tTrain Data (Original)  Memory Usage: 278.73 MB (2.6% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['TransactionAmt', 'C1', 'C2', 'C3', 'C4', ...]\n",
      "\t\t('int', [])   : 41 | ['TransactionDT', 'ProductCD', 'card1', 'card2', 'card3', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 17 | ['TransactionAmt', 'C1', 'C2', 'C3', 'C4', ...]\n",
      "\t\t('int', [])   : 41 | ['TransactionDT', 'ProductCD', 'card1', 'card2', 'card3', ...]\n",
      "\t1.1s = Fit runtime\n",
      "\t58 features in original data used to generate 58 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 278.73 MB (2.6% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.58s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'accuracy'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "AutoGluon will early stop models using evaluation metric: 'accuracy'\n",
      "Fitting model: RandomForestClassifierGini ...\n",
      "\t0.9837\t = Validation accuracy score\n",
      "\t253.12s\t = Training runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Fitting model: RandomForestClassifierEntr ...\n",
      "\t0.9837\t = Validation accuracy score\n",
      "\t219.31s\t = Training runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierGini ...\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 205 due to low memory. Expected memory usage reduced from 21.85% -> 15.0% of available memory...\n",
      "\t0.9853\t = Validation accuracy score\n",
      "\t151.05s\t = Training runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: ExtraTreesClassifierEntr ...\n",
      "\tWarning: Reducing model 'n_estimators' from 300 -> 194 due to low memory. Expected memory usage reduced from 23.19% -> 15.0% of available memory...\n",
      "\t0.9859\t = Validation accuracy score\n",
      "\t134.07s\t = Training runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierUnif ...\n",
      "\t0.9641\t = Validation accuracy score\n",
      "\t10.59s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: KNeighborsClassifierDist ...\n",
      "\t0.9683\t = Validation accuracy score\n",
      "\t10.36s\t = Training runtime\n",
      "\t0.08s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifier ...\n",
      "\t0.9727\t = Validation accuracy score\n",
      "\t6.83s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierXT ...\n",
      "\t0.9717\t = Validation accuracy score\n",
      "\t5.5s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: CatboostClassifier ...\n",
      "\t0.9702\t = Validation accuracy score\n",
      "\t4.68s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: NeuralNetClassifier ...\n",
      "\t0.9854\t = Validation accuracy score\n",
      "\t2312.53s\t = Training runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Fitting model: LightGBMClassifierCustom ...\n",
      "\t0.965\t = Validation accuracy score\n",
      "\t2.4s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: weighted_ensemble_k0_l1 ...\n",
      "\t0.9866\t = Validation accuracy score\n",
      "\t2.13s\t = Training runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 3142.16s ...\n"
     ]
    }
   ],
   "source": [
    "from autogluon import TabularPrediction as task\n",
    "\n",
    "predictor = task.fit(train_data=X_, label='isFraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance = predictor.predict_proba(test_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00154731, 0.03698877, 0.00699764, ..., 0.00305878, 0.00643699,\n",
       "       0.04293175], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame({'TransactionID': test['TransactionID'].values.tolist(),\n",
    "                    'isFraud': performance.tolist()\n",
    "                   })\n",
    "\n",
    "sub.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
